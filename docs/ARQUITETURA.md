# ğŸ—ï¸ Projeto: PrevisÃ£o de CÃ¢ncer de Mama â€” Documento de Arquitetura

> **VersÃ£o:** 1.0  
> **Data:** 19/02/2026  
> **Status:** Planejamento  
> **ReferÃªncia:** [Breast Cancer Wisconsin SVM Classification (Kaggle)](https://www.kaggle.com/code/buddhiniw/breast-cancer-prediction/notebook)

---

## ğŸ“‹ Ãndice

1. [VisÃ£o Geral do Projeto](#1-visÃ£o-geral-do-projeto)
2. [Dataset â€” AnÃ¡lise e Justificativas](#2-dataset--anÃ¡lise-e-justificativas)
3. [Pipeline de Machine Learning â€” Etapas e DecisÃµes](#3-pipeline-de-machine-learning--etapas-e-decisÃµes)
4. [Arquitetura do Sistema](#4-arquitetura-do-sistema)
5. [Modelagem do Banco de Dados (PostgreSQL)](#5-modelagem-do-banco-de-dados-postgresql)
6. [Estrutura de DiretÃ³rios](#6-estrutura-de-diretÃ³rios)
7. [Stack TecnolÃ³gica â€” Justificativas](#7-stack-tecnolÃ³gica--justificativas)
8. [Funcionalidades da Interface Web](#8-funcionalidades-da-interface-web)
9. [Roadmap de ImplementaÃ§Ã£o](#9-roadmap-de-implementaÃ§Ã£o)

---

## 1. VisÃ£o Geral do Projeto

### Objetivo
Construir uma aplicaÃ§Ã£o web profissional e interativa que reproduza e **expanda** o pipeline de classificaÃ§Ã£o de cÃ¢ncer de mama do notebook de referÃªncia, transformando uma anÃ¡lise estÃ¡tica em uma experiÃªncia visual, educativa e funcional.

### O que o notebook original faz
| Etapa | O que faz | LimitaÃ§Ã£o |
|-------|-----------|-----------|
| Data Loading | `pd.read_csv()` do Kaggle | Sem persistÃªncia, sem versionamento |
| Data Cleaning | Remove `id` e `Unnamed: 32` | Sem log de transformaÃ§Ãµes |
| EDA | GrÃ¡ficos estÃ¡ticos (matplotlib/seaborn) | NÃ£o interativos, sem filtros |
| Preprocessing | Encoding, Split, Imputer, Scaler | Sem rastreabilidade dos parÃ¢metros |
| Modeling | SVM Linear + SVM RBF | Apenas 2 modelos, sem comparaÃ§Ã£o estruturada |
| Evaluation | Accuracy, Confusion Matrix, Report | Sem persistÃªncia de mÃ©tricas |

### O que nosso projeto vai fazer
| Etapa | Nosso Approach | Vantagem |
|-------|---------------|----------|
| Data Storage | PostgreSQL relacional | PersistÃªncia, queries, integridade |
| Data Pipeline | ETL automatizado com log | Reprodutibilidade total |
| EDA | Plotly.js interativo no browser | Zoom, hover, filtros, tooltips |
| Preprocessing | Pipeline parametrizÃ¡vel via API | ConfigurÃ¡vel e rastreÃ¡vel |
| Modeling | SVM + Random Forest + LogReg + KNN | ComparaÃ§Ã£o rica de trade-offs |
| Evaluation | Dashboard comparativo em tempo real | MÃ©tricas lado a lado, visual |
| Interface | React + TypeScript SPA | Profissional, responsiva, moderna |

---

## 2. Dataset â€” AnÃ¡lise e Justificativas

### Fonte
- **Nome:** Breast Cancer Wisconsin (Diagnostic) Data Set
- **Origem:** UCI Machine Learning Repository
- **Coleta:** Imagens FNA (Fine Needle Aspirate) de massas mamÃ¡rias
- **Amostras:** 569 (357 benignas + 212 malignas)

### Estrutura das Features (30 features numÃ©ricas)

As features sÃ£o computadas a partir de imagens digitalizadas de aspiraÃ§Ãµes por agulha fina (FNA). Para **cada nÃºcleo celular**, 10 caracterÃ­sticas sÃ£o medidas:

| Feature | DescriÃ§Ã£o | Por que Ã© relevante |
|---------|-----------|-------------------|
| `radius` | MÃ©dia das distÃ¢ncias do centro aos pontos do perÃ­metro | Tumores malignos tendem a ser maiores |
| `texture` | Desvio padrÃ£o dos valores de escala de cinza | Textura irregular indica malignidade |
| `perimeter` | PerÃ­metro do nÃºcleo | Correlacionado com tamanho/forma |
| `area` | Ãrea do nÃºcleo | Tumores malignos tÃªm Ã¡rea maior |
| `smoothness` | VariaÃ§Ã£o local nos comprimentos do raio | Suavidade da borda do nÃºcleo |
| `compactness` | (perÃ­metroÂ² / Ã¡rea) - 1.0 | Forma irregular = mais compacto |
| `concavity` | Severidade das porÃ§Ãµes cÃ´ncavas do contorno | Concavidades profundas â†’ maligno |
| `concave_points` | NÃºmero de porÃ§Ãµes cÃ´ncavas | Quanto mais pontos cÃ´ncavos â†’ pior |
| `symmetry` | Simetria do nÃºcleo | Assimetria indica crescimento anormal |
| `fractal_dimension` | AproximaÃ§Ã£o "coastline" - 1 | Complexidade da borda |

Para cada uma dessas 10, sÃ£o calculados **3 agregadores**:
- **mean** â€” MÃ©dia de todos os nÃºcleos na imagem
- **se** â€” Erro padrÃ£o (variabilidade entre nÃºcleos)
- **worst** â€” MÃ©dia dos 3 piores valores (mais extremos)

> **Total: 10 Ã— 3 = 30 features preditivas**

### Colunas a remover e justificativa
| Coluna | Motivo da remoÃ§Ã£o |
|--------|------------------|
| `id` | Identificador arbitrÃ¡rio, sem valor preditivo. MantÃª-lo causaria data leakage |
| `Unnamed: 32` | Coluna completamente vazia (0 valores nÃ£o-nulos), artefato do CSV |

### Qualidade dos dados
- **Sem valores Missing:** 569/569 em todas as 30 features â†’ nenhuma imputaÃ§Ã£o necessÃ¡ria
- **Sem duplicatas:** 0 registros duplicados
- **Desbalanceamento leve:** 62.7% benigno vs 37.3% maligno â†’ aceitÃ¡vel, sem necessidade de SMOTE/undersampling

---

## 3. Pipeline de Machine Learning â€” Etapas e DecisÃµes

### ETAPA 1: Carregamento e Limpeza

```
CSV â†’ PostgreSQL â†’ DataFrame limpo
```

**DecisÃµes:**
- **Por que PostgreSQL vs CSV direto?**
  - PersistÃªncia entre sessÃµes
  - Queries SQL para exploraÃ§Ã£o rÃ¡pida
  - Integridade referencial entre tabelas (dados, resultados, mÃ©tricas)
  - Suporte a mÃºltiplos usuÃ¡rios simultÃ¢neos
  - Versionamento de experimentos

### ETAPA 2: AnÃ¡lise ExploratÃ³ria (EDA)

**O que o notebook faz â†’ O que nÃ³s faremos:**

| AnÃ¡lise | Original (estÃ¡tico) | Nosso (interativo) |
|---------|---------------------|-------------------|
| DistribuiÃ§Ã£o do diagnÃ³stico | `sns.countplot` | Plotly donut/bar com % e contagem |
| Histogramas das features | `sns.histplot` com KDE | Plotly com seletor de feature, toggle KDE |
| Boxplots por diagnÃ³stico | `sns.boxplot` individual | Grid comparativo com filtros |
| Scatter plots | `sns.scatterplot` fixo | Scatter com seletor X/Y, colorido por classe |
| Heatmap de correlaÃ§Ã£o | `sns.heatmap` estÃ¡tico | Heatmap interativo com hover, filtro por threshold |

**Por que cada grÃ¡fico foi escolhido:**

1. **Countplot / Donut â†’ DistribuiÃ§Ã£o do Target**
   - *Por que:* Verificar desbalanceamento de classes. Se fosse severo (>80/20), precisarÃ­amos de tÃ©cnicas de resampling
   - *Resultado esperado:* 62.7% B / 37.3% M â†’ desbalanceamento moderado, aceitÃ¡vel

2. **Histogramas com KDE â†’ DistribuiÃ§Ã£o de Features**
   - *Por que:* Visualizar se as distribuiÃ§Ãµes de cada feature diferem entre B e M. Features com distribuiÃ§Ãµes separadas sÃ£o mais discriminativas
   - *Features chave:* `radius_mean`, `perimeter_mean`, `area_mean` mostram separaÃ§Ã£o clara

3. **Boxplots â†’ Outliers e Separabilidade**
   - *Por que:* Identificar outliers que podem afetar o SVM e confirmar quais features separam melhor as classes
   - *Insight:* `radius_worst`, `perimeter_worst`, `area_worst` tÃªm separaÃ§Ã£o nÃ­tida entre B e M

4. **Scatter Plots â†’ RelaÃ§Ãµes entre Features**
   - *Por que:* Verificar se a fronteira de decisÃ£o Ã© linear ou nÃ£o-linear (justifica a escolha de kernel RBF)
   - *Insight:* `radius_mean` vs `area_mean` mostra clusters com fronteira curva â†’ SVM linear nÃ£o Ã© suficiente

5. **Heatmap de CorrelaÃ§Ã£o â†’ Multicolinearidade**
   - *Por que:* Features altamente correlacionadas (>0.9) sÃ£o redundantes e podem afetar performance
   - *Insight:* radius/perimeter/area sÃ£o fortemente correlacionados â†’ confirma redundÃ¢ncia, mas SVM lida bem com isso

### ETAPA 3: PrÃ©-processamento

**3.1 Encoding do Target**
```python
diagnosis: M â†’ 1 (maligno), B â†’ 0 (benigno)
```
- *Por que:* Algoritmos de ML requerem valores numÃ©ricos
- *Por que 1=Maligno:* ConvenÃ§Ã£o mÃ©dica â€” a classe positiva (1) Ã© a doenÃ§a, facilitando interpretaÃ§Ã£o de recall/precision

**3.2 Train/Test Split (75/25)**
- *Por que 75/25:* PadrÃ£o da literatura para datasets de tamanho mÃ©dio (~500 amostras)
- *Por que nÃ£o 80/20:* Com 569 amostras, 25% teste = ~142 amostras, suficiente para avaliaÃ§Ã£o robusta
- *random_state=42:* Reprodutibilidade garantida

**3.3 ImputaÃ§Ã£o (SimpleImputer - mÃ©dia)**
- *Por que incluir mesmo sem missing values:* Robustez do pipeline. Se novos dados tiverem missings, o pipeline nÃ£o quebra
- *Por que mÃ©dia:* Para features com distribuiÃ§Ã£o aproximadamente normal, a mÃ©dia Ã© o estimador mais estÃ¡vel

**3.4 Feature Scaling (StandardScaler)**
```
z = (x - Î¼) / Ïƒ
```
- *Por que Ã© CRÃTICO para SVM:* O SVM calcula distÃ¢ncias entre pontos. Sem escalonamento, features com ranges maiores (ex: `area_mean` ~100-2500) dominariam features com ranges menores (ex: `smoothness_mean` ~0.05-0.16)
- *Por que StandardScaler vs MinMaxScaler:* StandardScaler Ã© mais robusto a outliers e produz distribuiÃ§Ãµes centradas em 0, ideal para kernels SVM
- *Por que fit no treino e transform no teste:* Prevenir data leakage â€” o teste nÃ£o pode influenciar as estatÃ­sticas de normalizaÃ§Ã£o

### ETAPA 4: Modelagem

**Modelos escolhidos e justificativas:**

| Modelo | Por que incluir | HiperparÃ¢metros | Justificativa dos parÃ¢metros |
|--------|----------------|-----------------|------------------------------|
| **SVM Linear** | Baseline â€” verificar se a fronteira Ã© linearmente separÃ¡vel | `kernel='linear', C=1` | C=1 Ã© o default, bom equilÃ­brio entre margem e erro |
| **SVM RBF** | Capturar fronteiras nÃ£o-lineares (como visto nos scatter plots) | `kernel='rbf', C=2, gamma=0.01` | C=2 permite mais flexibilidade; gamma=0.01 evita overfitting |
| **Random Forest** | Ensemble de Ã¡rvores â€” robusto, fornece feature importance | `n_estimators=100, random_state=42` | 100 Ã¡rvores Ã© padrÃ£o estÃ¡vel |
| **Logistic Regression** | Modelo interpretÃ¡vel â€” fornece probabilidades e coeficientes | `max_iter=1000, random_state=42` | max_iter alto para garantir convergÃªncia |
| **KNN** | ComparaÃ§Ã£o nÃ£o-paramÃ©trica baseada em vizinhanÃ§a | `n_neighbors=5` | k=5 Ã© padrÃ£o, previne overfitting |

**Por que esses 5 modelos especificamente:**
1. **Diversidade de famÃ­lias:** Linear (LogReg, SVM Linear), NÃ£o-linear (SVM RBF, RF, KNN)
2. **Interpretabilidade vs Performance:** LogReg Ã© interpretÃ¡vel, RF dÃ¡ feature importance, SVM maximiza performance
3. **Contexto mÃ©dico:** Em diagnÃ³stico, queremos **maximizar Recall** (minimizar falsos negativos = casos de cÃ¢ncer nÃ£o detectados)

### ETAPA 5: AvaliaÃ§Ã£o

**MÃ©tricas e por que cada uma importa:**

| MÃ©trica | O que mede | RelevÃ¢ncia clÃ­nica |
|---------|-----------|-------------------|
| **Accuracy** | % total de acertos | VisÃ£o geral, mas enganosa com dados desbalanceados |
| **Precision** | Dos que o modelo disse "maligno", quantos realmente sÃ£o | Evitar cirurgias/tratamentos desnecessÃ¡rios |
| **Recall (Sensibilidade)** | Dos que realmente sÃ£o malignos, quantos o modelo detectou | **MAIS IMPORTANTE** â€” nÃ£o perder diagnÃ³sticos de cÃ¢ncer |
| **F1-Score** | MÃ©dia harmÃ´nica de Precision e Recall | EquilÃ­brio entre as duas |
| **Confusion Matrix** | Tabela de VP, FP, VN, FN | VisualizaÃ§Ã£o direta dos erros |
| **ROC-AUC** | Ãrea sob a curva ROC | Capacidade discriminativa geral do modelo |
| **Cross-Validation** | MÃ©dia de performance em K folds | Robustez e generalizaÃ§Ã£o |

> âš ï¸ **DecisÃ£o crÃ­tica:** Em diagnÃ³stico mÃ©dico, **Recall > Precision**.  
> Um falso negativo (cÃ¢ncer nÃ£o detectado) Ã© **muito mais grave** que um falso positivo (alarme falso investigado por biÃ³psia).

---

## 4. Arquitetura do Sistema

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        FRONTEND (React + TypeScript)            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚ Dashboardâ”‚ â”‚   EDA    â”‚ â”‚ Modelos  â”‚ â”‚ PrediÃ§Ã£o â”‚          â”‚
â”‚  â”‚  Geral   â”‚ â”‚Interativoâ”‚ â”‚ComparaÃ§Ã£oâ”‚ â”‚  Online  â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜          â”‚
â”‚       â”‚             â”‚            â”‚             â”‚                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”          â”‚
â”‚  â”‚              Plotly.js (GrÃ¡ficos)                 â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚ HTTP/REST (JSON)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    BACKEND (FastAPI)                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚ /api/dataâ”‚ â”‚ /api/eda â”‚ â”‚/api/modelâ”‚ â”‚/api/pred â”‚          â”‚
â”‚  â”‚  CRUD    â”‚ â”‚ GrÃ¡ficos â”‚ â”‚Train/Evalâ”‚ â”‚ Inferir  â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜          â”‚
â”‚       â”‚             â”‚            â”‚             â”‚                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”          â”‚
â”‚  â”‚          Service Layer (scikit-learn)              â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚                         â”‚                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚         SQLAlchemy ORM + Alembic Migrations       â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚ SQL
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PostgreSQL                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚ samples  â”‚ â”‚ features â”‚ â”‚ models   â”‚ â”‚ metrics  â”‚          â”‚
â”‚  â”‚(amostras)â”‚ â”‚(metadata)â”‚ â”‚(treinadosâ”‚ â”‚(avaliaÃ§Ã£oâ”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 5. Modelagem do Banco de Dados (PostgreSQL)

### Diagrama Relacional

```sql
-- Tabela principal: armazena cada amostra do dataset
CREATE TABLE samples (
    id SERIAL PRIMARY KEY,
    original_id INTEGER,           -- ID original do dataset
    diagnosis VARCHAR(1) NOT NULL, -- 'M' ou 'B'
    diagnosis_encoded INTEGER,     -- 1 ou 0
    created_at TIMESTAMP DEFAULT NOW()
);

-- Tabela de features: valores numÃ©ricos de cada amostra
CREATE TABLE sample_features (
    id SERIAL PRIMARY KEY,
    sample_id INTEGER REFERENCES samples(id),
    feature_name VARCHAR(50) NOT NULL,
    feature_value FLOAT NOT NULL,
    feature_group VARCHAR(10),     -- 'mean', 'se', 'worst'
    feature_base VARCHAR(30)       -- 'radius', 'texture', etc.
);

-- DefiniÃ§Ã£o de features (metadata)
CREATE TABLE feature_definitions (
    id SERIAL PRIMARY KEY,
    name VARCHAR(50) UNIQUE NOT NULL,
    description TEXT,
    base_feature VARCHAR(30),
    aggregation VARCHAR(10),       -- 'mean', 'se', 'worst'
    unit VARCHAR(20),
    min_value FLOAT,
    max_value FLOAT,
    clinical_relevance TEXT
);

-- Experimentos de treinamento
CREATE TABLE experiments (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100),
    description TEXT,
    test_size FLOAT DEFAULT 0.25,
    random_state INTEGER DEFAULT 42,
    scaler_type VARCHAR(30) DEFAULT 'StandardScaler',
    created_at TIMESTAMP DEFAULT NOW()
);

-- Modelos treinados
CREATE TABLE trained_models (
    id SERIAL PRIMARY KEY,
    experiment_id INTEGER REFERENCES experiments(id),
    model_type VARCHAR(50) NOT NULL,   -- 'SVM_Linear', 'SVM_RBF', etc.
    hyperparameters JSONB,              -- {'C': 1, 'kernel': 'linear'}
    model_blob BYTEA,                   -- modelo serializado (pickle)
    training_time_ms INTEGER,
    created_at TIMESTAMP DEFAULT NOW()
);

-- MÃ©tricas de avaliaÃ§Ã£o
CREATE TABLE model_metrics (
    id SERIAL PRIMARY KEY,
    model_id INTEGER REFERENCES trained_models(id),
    metric_name VARCHAR(30),    -- 'accuracy', 'precision', 'recall', etc.
    metric_value FLOAT,
    class_label VARCHAR(10),    -- 'B', 'M', 'weighted', 'macro'
    created_at TIMESTAMP DEFAULT NOW()
);

-- Resultados de prediÃ§Ã£o (confusion matrix detalhada)
CREATE TABLE predictions (
    id SERIAL PRIMARY KEY,
    model_id INTEGER REFERENCES trained_models(id),
    sample_id INTEGER REFERENCES samples(id),
    true_label INTEGER,
    predicted_label INTEGER,
    prediction_probability FLOAT,
    is_train BOOLEAN DEFAULT FALSE
);

-- CorrelaÃ§Ãµes entre features (cache)
CREATE TABLE feature_correlations (
    id SERIAL PRIMARY KEY,
    feature_a VARCHAR(50),
    feature_b VARCHAR(50),
    correlation_value FLOAT,
    experiment_id INTEGER REFERENCES experiments(id)
);
```

### Por que modelar assim (e nÃ£o simplesmente uma tabela flat)?

1. **`samples` + `sample_features` (normalizado):** Permite queries flexÃ­veis como "me dÃª todas as amostras onde `radius_mean > 15`" sem hardcode de colunas
2. **`feature_definitions`:** Metadata clinica de cada feature para tooltips na interface  
3. **`experiments`:** Cada execuÃ§Ã£o do pipeline Ã© um experimento versionado â€” permite comparar configuraÃ§Ãµes
4. **`trained_models` + `model_metrics`:** Rastreabilidade completa â€” qual modelo, com quais parÃ¢metros, produziu quais mÃ©tricas
5. **`predictions`:** Permite recalcular confusion matrix, ROC curves, etc. sob demanda
6. **`feature_correlations`:** Cache para evitar recÃ¡lculo pesado na interface

---

## 6. Estrutura de DiretÃ³rios

```
CancerMama/
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ ARQUITETURA.md              â† Este documento
â”‚   â””â”€â”€ API.md                       â† DocumentaÃ§Ã£o dos endpoints
â”‚
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ main.py                  â† FastAPI app entry point
â”‚   â”‚   â”œâ”€â”€ config.py                â† ConfiguraÃ§Ãµes (DB, etc.)
â”‚   â”‚   â”œâ”€â”€ database.py              â† Engine SQLAlchemy + Session
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ models/                  â† SQLAlchemy ORM Models
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ sample.py
â”‚   â”‚   â”‚   â”œâ”€â”€ feature.py
â”‚   â”‚   â”‚   â”œâ”€â”€ experiment.py
â”‚   â”‚   â”‚   â””â”€â”€ prediction.py
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ schemas/                 â† Pydantic Schemas (request/response)
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ sample.py
â”‚   â”‚   â”‚   â”œâ”€â”€ eda.py
â”‚   â”‚   â”‚   â”œâ”€â”€ model.py
â”‚   â”‚   â”‚   â””â”€â”€ prediction.py
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ routers/                 â† API Endpoints
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ data.py              â† /api/data â€” CRUD de amostras
â”‚   â”‚   â”‚   â”œâ”€â”€ eda.py               â† /api/eda â€” grÃ¡ficos e estatÃ­sticas
â”‚   â”‚   â”‚   â”œâ”€â”€ preprocessing.py     â† /api/preprocessing â€” pipeline
â”‚   â”‚   â”‚   â”œâ”€â”€ models.py            â† /api/models â€” treino e avaliaÃ§Ã£o
â”‚   â”‚   â”‚   â””â”€â”€ predictions.py       â† /api/predictions â€” inferÃªncia
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ services/                â† LÃ³gica de negÃ³cio
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ data_service.py      â† ETL, carga do CSV â†’ PostgreSQL
â”‚   â”‚   â”‚   â”œâ”€â”€ eda_service.py       â† CÃ¡lculos estatÃ­sticos
â”‚   â”‚   â”‚   â”œâ”€â”€ ml_service.py        â† Treinamento e avaliaÃ§Ã£o
â”‚   â”‚   â”‚   â””â”€â”€ prediction_service.py
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ ml/                      â† Pipeline de Machine Learning
â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚       â”œâ”€â”€ preprocessing.py     â† Scaler, Imputer, Encoder
â”‚   â”‚       â”œâ”€â”€ training.py          â† Treino dos modelos
â”‚   â”‚       â”œâ”€â”€ evaluation.py        â† MÃ©tricas, confusion matrix
â”‚   â”‚       â””â”€â”€ models_config.py     â† Config dos 5 modelos
â”‚   â”‚
â”‚   â”œâ”€â”€ alembic/                     â† Migrations do banco
â”‚   â”‚   â””â”€â”€ versions/
â”‚   â”œâ”€â”€ alembic.ini
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ Dockerfile
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â”œâ”€â”€ layout/              â† Header, Sidebar, Footer
â”‚   â”‚   â”‚   â”œâ”€â”€ charts/              â† Componentes Plotly reutilizÃ¡veis
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ DistributionChart.tsx
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ CorrelationHeatmap.tsx
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ BoxPlotGrid.tsx
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ScatterPlot.tsx
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ConfusionMatrix.tsx
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ ROCCurve.tsx
â”‚   â”‚   â”‚   â””â”€â”€ ui/                  â† Buttons, Cards, Tables
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ pages/
â”‚   â”‚   â”‚   â”œâ”€â”€ Dashboard.tsx        â† VisÃ£o geral do projeto
â”‚   â”‚   â”‚   â”œâ”€â”€ DataExplorer.tsx     â† Explorar o dataset
â”‚   â”‚   â”‚   â”œâ”€â”€ EDA.tsx              â† AnÃ¡lise exploratÃ³ria interativa
â”‚   â”‚   â”‚   â”œâ”€â”€ Preprocessing.tsx    â† Visualizar pipeline
â”‚   â”‚   â”‚   â”œâ”€â”€ Models.tsx           â† ComparaÃ§Ã£o de modelos
â”‚   â”‚   â”‚   â””â”€â”€ Prediction.tsx       â† PrediÃ§Ã£o com novos dados
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â””â”€â”€ api.ts               â† Client HTTP (axios/fetch)
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ types/
â”‚   â”‚   â”‚   â””â”€â”€ index.ts             â† TypeScript interfaces
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ App.tsx
â”‚   â”‚   â””â”€â”€ main.tsx
â”‚   â”‚
â”‚   â”œâ”€â”€ package.json
â”‚   â”œâ”€â”€ tsconfig.json
â”‚   â”œâ”€â”€ vite.config.ts
â”‚   â””â”€â”€ Dockerfile
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ data.csv                     â† Dataset original (jÃ¡ baixado)
â”‚
â”œâ”€â”€ docker-compose.yml               â† PostgreSQL + Backend + Frontend
â””â”€â”€ README.md
```

---

## 7. Stack TecnolÃ³gica â€” Justificativas

### Backend: FastAPI
| CritÃ©rio | Justificativa |
|----------|--------------|
| Performance | Async nativo, 3-10x mais rÃ¡pido que Flask |
| DocumentaÃ§Ã£o | Swagger/OpenAPI gerado automaticamente |
| Type Safety | Pydantic para validaÃ§Ã£o de dados |
| ML Integration | Integra nativamente com numpy/pandas |
| Data Science | PadrÃ£o da indÃºstria para APIs de ML |

### Frontend: React + TypeScript + Plotly.js
| CritÃ©rio | Justificativa |
|----------|--------------|
| Interatividade | Plotly.js oferece zoom, hover, seleÃ§Ã£o, pan nativos |
| ComponentizaÃ§Ã£o | Cada grÃ¡fico Ã© um componente reutilizÃ¡vel |
| Type Safety | TypeScript previne erros em dados complexos |
| Ecossistema | Maior ecossistema de bibliotecas UI |
| Performance | Virtual DOM para re-renders eficientes em dashboards pesados |

### Banco: PostgreSQL
| CritÃ©rio | Justificativa |
|----------|--------------|
| JSONB | Armazenar hiperparÃ¢metros e configuraÃ§Ãµes como JSON nativo |
| Performance | Ãndices e queries otimizados para agregaÃ§Ãµes analÃ­ticas |
| Integridade | Foreign keys, constraints, transactions ACID |
| Escalabilidade | Suportaria milhÃµes de registros se o dataset crescer |
| Ferramental | pgAdmin, extensÃµes (PostGIS, pg_trgm), backup nativo |

### ORM: SQLAlchemy + Alembic
| CritÃ©rio | Justificativa |
|----------|--------------|
| Migrations | Alembic gerencia evoluÃ§Ãµes do schema de forma versionada |
| AbstraÃ§Ã£o | ORM permite trocar de banco sem reescrever queries |
| Raw SQL | Permite SQL direto quando performance importa |

---

## 8. Funcionalidades da Interface Web

### PÃ¡gina 1: Dashboard Geral
- KPIs: total de amostras, % benigno/maligno, melhor modelo, melhor recall
- Mini-grÃ¡ficos resumo
- Status do pipeline (dados carregados, modelos treinados)

### PÃ¡gina 2: Explorador de Dados
- Tabela interativa com paginaÃ§Ã£o, busca e ordenaÃ§Ã£o
- EstatÃ­sticas descritivas por coluna (hover)
- Download filtrado

### PÃ¡gina 3: EDA Interativa
- **DistribuiÃ§Ã£o do Target:** Donut chart + bar chart com contagens
- **Histogramas:** Seletor de feature, toggle KDE, split por diagnÃ³stico
- **Boxplots:** Grade comparativa 2Ã—5 (mean vs worst), filtro por grupo
- **Scatter Plot:** Seletores X/Y livres, colorido por diagnÃ³stico
- **Heatmap de CorrelaÃ§Ã£o:** Interativo com hover, slider de threshold, clusterizaÃ§Ã£o
- **Pairplot:** Features top-5 mais discriminativas

### PÃ¡gina 4: PrÃ©-processamento
- VisualizaÃ§Ã£o antes/depois do scaling
- DistribuiÃ§Ã£o do train/test split
- Pipeline visual (diagrama de fluxo)

### PÃ¡gina 5: ComparaÃ§Ã£o de Modelos
- Tabela comparativa: Accuracy, Precision, Recall, F1, AUC
- Confusion Matrix lado a lado (5 modelos)
- Curvas ROC sobrepostas
- Feature Importance (Random Forest)
- Tempo de treinamento

### PÃ¡gina 6: PrediÃ§Ã£o Online
- FormulÃ¡rio com os 30 campos (com tooltips explicando cada feature)
- Resultado: Benigno/Maligno + probabilidade
- Seletor de modelo para comparar prediÃ§Ãµes

---

## 9. Roadmap de ImplementaÃ§Ã£o

### Fase 1 â€” Infraestrutura (FundaÃ§Ã£o)
- [ ] Setup do projeto (diretÃ³rios, configs)
- [ ] Docker Compose com PostgreSQL
- [ ] Backend FastAPI bÃ¡sico + SQLAlchemy + Alembic
- [ ] Migrations do banco de dados
- [ ] ETL: CSV â†’ PostgreSQL

### Fase 2 â€” API de Dados e EDA
- [ ] Endpoints CRUD de dados (/api/data)
- [ ] Endpoints de estatÃ­sticas (/api/eda)
- [ ] CÃ¡lculos: distribuiÃ§Ã£o, correlaÃ§Ã£o, descritivos

### Fase 3 â€” Pipeline de ML
- [ ] Pipeline de preprocessing parametrizÃ¡vel
- [ ] Treinamento dos 5 modelos
- [ ] AvaliaÃ§Ã£o e persistÃªncia de mÃ©tricas
- [ ] Cross-validation

### Fase 4 â€” Frontend Base
- [ ] Setup React + TypeScript + Vite
- [ ] Layout: Sidebar, Header, Routing
- [ ] IntegraÃ§Ã£o com API (axios)
- [ ] Dashboard Geral

### Fase 5 â€” VisualizaÃ§Ãµes Interativas
- [ ] Componentes Plotly: histogramas, boxplots, scatter
- [ ] Heatmap de correlaÃ§Ã£o interativo
- [ ] Confusion matrix comparativa
- [ ] Curvas ROC

### Fase 6 â€” PrediÃ§Ã£o e Polimento
- [ ] FormulÃ¡rio de prediÃ§Ã£o online
- [ ] Responsividade mobile
- [ ] Dark mode
- [ ] DocumentaÃ§Ã£o final

---

> **PrÃ³ximo passo:** Confirmar esta arquitetura e iniciar a Fase 1 â€” Setup da infraestrutura.
